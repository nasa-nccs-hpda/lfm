{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b872aa-c1e9-42b8-b966-2ca81a5c9315",
   "metadata": {},
   "source": [
    "# LFM Toy Model\n",
    "This notebook is used to fine-tune a DinoV3 toy model on Lunar data. \n",
    "\n",
    "# Model specifications\n",
    "The SAT-493M ViT-L/16 distilled DinoV3 encoder was used (trained on Satellite data). All encoder parameters were unfrozen for fine-tuning. See the [DinoV3 repo](https://github.com/facebookresearch/dinov3) for more info. \n",
    "\n",
    "## Input data specifications\n",
    "The vis data, (hosted at /explore/nobackup/projects/lfm/rawdata/Lunar/LowRes_MLDataset_v1_bilinear), was preprocessed by extracting the following bands and normalizing values to [0,1] range: [643, 566, 415]. Data was saved in (3, 300, 300) shape .npy files under the LFM project space (explore/nobackup/projects/lfm/vis_chips). \n",
    "\n",
    "## Label specifications\n",
    "Labels were processed from the annotations JSON file. Annotations were sorted by corresponding filename, then all labels for a given filename were saved single composite (300, 300) shape .npy images under the LFM project space (explore/nobackup/projects/lfm/vis_chips). \n",
    "\n",
    "## Input/label matching\n",
    "Labels and inputs were matched by asset ID, as well as tile row/column ID. \n",
    "\n",
    "## Training specifications\n",
    "Model was trained on 500 input/label pairs for 50 epochs, using a PRISM JupyterHub job on 4 V100 GPUs (1 V100 will also work, but will be slower). The parameters used were: \"combined\" loss function (Dice loss + Binary CE), 1e-4 LR, AdamW optimizer, and Cosine Annealing LR scheduling. A train/val split of 80/20% was used as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65889f6-4178-498f-8ffe-9aa405928235",
   "metadata": {},
   "source": [
    "## Imports, Dino Repo Clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5affb6f2-7114-45e7-af1a-0fefc17329a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from model import DINOSegmentation\n",
    "from dataset import get_dataloaders\n",
    "from driver import train_model\n",
    "\n",
    "# Notebook settings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d85927-0978-48d0-b36d-72e2dc6a1fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'dinov3' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Notebook requires access to models on GitHub (see their README)\n",
    "!git clone https://github.com/facebookresearch/dinov3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f314109-cf55-417f-b553-7da23b0cdcba",
   "metadata": {},
   "source": [
    "## Main workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7cd289-3975-4254-8d2c-faafee3babd4",
   "metadata": {},
   "source": [
    "### User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9199a001-42fb-4a2d-996a-ae6d6ad6c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ./outputs\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Weights URL (received after registering for DINOV3)\n",
    "weights_URL = (\n",
    "    \"https://dinov3.llamameta.net/dinov3_vitl16/\"\n",
    "    \"dinov3_vitl16_pretrain_sat493m-eadcf0ff.pth\"\n",
    "    \"?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiNDloYXZtdThkZGh3eGw3aH\"\n",
    "    \"JwNjQwa3E3IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZGlub3YzLmxsYW1hbWV0YS5uZXR\"\n",
    "    \"cLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE\"\n",
    "    \"3Njc5OTI2Njl9fX1dfQ__\"\n",
    "    \"&Signature=neHREO7xc90azhmnF3r9qPztYJ5L2wO-EZkVKh6ECzR5H2YGzdK3dcF\"\n",
    "    \"WQISNb6xYo3R5EO39FKJ7bwELXA%7EgoBqDbk-jm-9n9%7EVxtEOmWVx73usrILMwhyi\"\n",
    "    \"cP5-448rbnUzOEM0lPkGS829mOBJkaSxxSsbkQ0VpVBcScNEFcpaNOZ--BeHxCHdTFV\"\n",
    "    \"NGkhlEaCYPUbYyHYbTgDQntH2AsKYJTWw4NIEZJZLX9wjCOYKQ-YG86d0HJAvsdF79X\"\n",
    "    \"vITPgJSA0U-4Z1CzIkQhZb0N-7-XnbZmnJJi42xnNS0DsB6CTedxq0FAfiYklBY77wT\"\n",
    "    \"JrYLba%7Epkap23ymoUTxDXA__\"\n",
    "    \"&Key-Pair-Id=K15QRJLYKIFSLZ\"\n",
    "    \"&Download-Request-ID=1618342689192585\"\n",
    ")\n",
    "\n",
    "# Data paths\n",
    "INPUT_DIR = \"/explore/nobackup/people/ajkerr1/Lunar_FM\"\n",
    "IMAGE_DIR = f\"{INPUT_DIR}/vis_chips/chips\"\n",
    "LABEL_DIR = f\"{INPUT_DIR}/vis_chips/labels_npy\"\n",
    "\n",
    "# Output dir (create this if not already created)\n",
    "OUTPUT_DIR = \"./outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Location of cloned dinov3 repo\n",
    "REPO_DIR = \"./dinov3\"\n",
    "\n",
    "# Dataset parameters\n",
    "MAX_SAMPLES = 500  # Set to None to use all available samples, or an integer to limit\n",
    "TRAIN_SPLIT = 0.8  # 80% train, 20% validation\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 4\n",
    "LOSS_TYPE = \"combined\"  # Combined Dice + Binary CE loss\n",
    "\n",
    "# Model parameters\n",
    "TARGET_SIZE = (304, 304)  # Input size for DINO model\n",
    "N_CLASSES = 2  # Binary segmentation (background, crater)\n",
    "FREEZE_ENCODER = True\n",
    "\n",
    "# Visualization and saving\n",
    "CHECKPOINT_EVERY = 10  # Save checkpoint every N epochs\n",
    "VISUALIZE_EVERY = 10  # Create visualizations every N epochs\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee23de-ee8d-4a92-a894-3afacb3b6667",
   "metadata": {},
   "source": [
    "### Training code\n",
    "1. Create dataloaders from files on /nobackup space.\n",
    "2. Load DinoV3 encoder, create encoder/decoder finetuning model.\n",
    "3. Train model and print training stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28f12b4-46d2-4fb9-a55f-967916c53b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: Creating dataloaders.\n",
      "============================================================\n",
      "Computing dataset statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing dataset statistics:   1%|▏         | 111/7530 [00:00<00:06, 1102.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image shape: (3, 300, 300), dtype: float64\n",
      "Value range: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing dataset statistics: 100%|██████████| 7530/7530 [00:06<00:00, 1137.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7530 valid images out of 7530 total\n",
      "Mean (RGB): [0.32744208 0.32249309 0.302985  ]\n",
      "Std (RGB): [0.15045737 0.15014801 0.14386101]\n",
      "✓ Saved statistics to ./outputs\n",
      "Limited to 500 samples\n",
      "Found 500 matched image-label pairs\n",
      "Train samples: 400\n",
      "Val samples: 100\n",
      "Train batches: 25\n",
      "Val batches: 7\n",
      "\n",
      "============================================================\n",
      "STEP 2: Loading DINO encoder and creating model.\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTEP 2: Loading DINO encoder and creating model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mREPO_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdinov3_vitl16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_URL\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder loaded with pretrained weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Create model with DINO segmentation head, UNet decoder (see model.py)\u001b[39;00m\n",
      "File \u001b[0;32m/panfs/ccds02/app/modules/miniforge/platform/x86_64/rhel/8.10/24.9.0/envs/torch/lib/python3.11/site-packages/torch/hub.py:647\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgithub\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     repo_or_dir \u001b[38;5;241m=\u001b[39m _get_cache_or_reload(\n\u001b[1;32m    639\u001b[0m         repo_or_dir,\n\u001b[1;32m    640\u001b[0m         force_reload,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m         skip_validation\u001b[38;5;241m=\u001b[39mskip_validation,\n\u001b[1;32m    645\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/panfs/ccds02/app/modules/miniforge/platform/x86_64/rhel/8.10/24.9.0/envs/torch/lib/python3.11/site-packages/torch/hub.py:677\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _add_to_sys_path(hubconf_dir):\n\u001b[1;32m    676\u001b[0m     hubconf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m--> 677\u001b[0m     hub_module \u001b[38;5;241m=\u001b[39m \u001b[43m_import_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODULE_HUBCONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhubconf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     entry \u001b[38;5;241m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m    680\u001b[0m     model \u001b[38;5;241m=\u001b[39m entry(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/panfs/ccds02/app/modules/miniforge/platform/x86_64/rhel/8.10/24.9.0/envs/torch/lib/python3.11/site-packages/torch/hub.py:115\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m    113\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, Loader)\n\u001b[0;32m--> 115\u001b[0m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/Lunar_FM/dinov3-finetune-copy/./dinov3/hubconf.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_de\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdinotxt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dinov3_vitl16_dinotxt_tet1280d20h24l\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_ms\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdepthers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_dd\n\u001b[1;32m     26\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/Lunar_FM/dinov3-finetune-copy/./dinov3/dinov3/hub/segmentors.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_segmentation_decoder\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbones\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     dinov3_vit7b16,\n\u001b[1;32m     14\u001b[0m     dinov3_vitl16,\n\u001b[1;32m     15\u001b[0m     Weights \u001b[38;5;28;01mas\u001b[39;00m BackboneWeights,\n\u001b[1;32m     16\u001b[0m     convert_path_or_url_to_url,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DINOV3_BASE_URL\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/Lunar_FM/dinov3-finetune-copy/./dinov3/dinov3/eval/segmentation/models/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_head\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearHead\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmask2former_head\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mask2FormerHead\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelWithIntermediateLayers\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackboneLayersSet\u001b[39;00m(Enum):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Set of intermediate layers to take from the backbone.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/Lunar_FM/dinov3-finetune-copy/./dinov3/dinov3/eval/utils.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetWithEnumeratedTargets, SamplerType, make_data_loader\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccumulators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoOpAccumulator, ResultsAccumulator\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricLogger\n\u001b[1;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdinov3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLossType\u001b[39;00m(Enum):\n",
      "File \u001b[0;32m/panfs/ccds02/nobackup/people/ajkerr1/Lunar_FM/dinov3-finetune-copy/./dinov3/dinov3/logging/__init__.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtermcolor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colored\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchDistributedEnvironment\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricLogger, SmoothedValue\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'termcolor'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE DATALOADERS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: Creating dataloaders.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_loader, val_loader, MEAN, STD = get_dataloaders(\n",
    "    image_dir=IMAGE_DIR,\n",
    "    label_dir=LABEL_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_split=TRAIN_SPLIT,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_size=TARGET_SIZE,\n",
    "    max_samples=MAX_SAMPLES,\n",
    "    seed=42,\n",
    "    stats_save_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ENCODER AND CREATE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Loading DINO encoder and creating model.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "encoder = torch.hub.load(\n",
    "    REPO_DIR,\n",
    "    'dinov3_vitl16',\n",
    "    source='local',\n",
    "    weights=weights_URL\n",
    ").to(device)\n",
    "\n",
    "print(\"Encoder loaded with pretrained weights.\")\n",
    "\n",
    "# Create model with DINO segmentation head, UNet decoder (see model.py)\n",
    "print(\"Creating DINO segmentation model with UNet decoder...\")\n",
    "model = DINOSegmentation(\n",
    "    encoder=encoder,\n",
    "    num_classes=N_CLASSES,\n",
    "    img_size=TARGET_SIZE\n",
    ").to(device)\n",
    "\n",
    "# Unfreeze encoder for full fine-tuning\n",
    "if FREEZE_ENCODER:\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    print(\"Encoder frozen (only decoder will be trained).\")\n",
    "else:\n",
    "    print(\"Encoder unfrozen! Full model will be trained.\")\n",
    "\n",
    "# ============================================================================\n",
    "# RUN TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting training.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    mode=\"train\",\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    checkpoint_every=CHECKPOINT_EVERY,\n",
    "    visualize_every=VISUALIZE_EVERY,\n",
    "    loss_type=LOSS_TYPE,\n",
    "    device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
